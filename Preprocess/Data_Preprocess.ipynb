{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMhWujeVbtHjjIW8JLHo7gi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **데이터 전처리 코드**"],"metadata":{"id":"4T9cJ4N0VVdh"}},{"cell_type":"markdown","source":["- 데이터 전처리: MinMax Scaler\n","- 데이터 증강: Sliding Window\n","\n","\n","\n","수정 사항\n","- Wafer_ID 별로 슬라이딩 윈도우 진행\n","- 학습셋: 정상 데이터(80%)\n","- 테스트셋: 정상 데이터(20%). 불량 데이터(100%)"],"metadata":{"id":"HOTOG4ijXNHA"}},{"cell_type":"markdown","source":["## **1. 드라이브 연결**"],"metadata":{"id":"-DJk6zaZVZ0x"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"qErgBPdKVNUR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770703240747,"user_tz":-540,"elapsed":18632,"user":{"displayName":"이성재","userId":"12219853136685213654"}},"outputId":"d3b84035-7841-41a0-a199-e33abaffda54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## **2. 파라미터 설정, 데이터 로드, 데이터셋 분리**"],"metadata":{"id":"Yur2TMgvVqRU"}},{"cell_type":"code","source":["# ==========================================\n","# 1. 라이브러리 임포트 및 설정\n","# ==========================================\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\n","from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, f1_score\n","import os\n","import math\n","\n","# CPU 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# ==========================================\n","# 2. 데이터 로드\n","# ==========================================\n","# 업로드된 파일명 사용 (환경에 맞게 경로 수정 가능)\n","file_path = \"/content/drive/MyDrive/ASK_2026_FDC/Dataset/MACHINE_Data.xlsx\"\n","\n","if os.path.exists(file_path):\n","    print(f\"Loading data from: {file_path}\")\n","    if file_path.endswith('.xlsx'):\n","        df = pd.read_excel(file_path)\n","    else:\n","        df = pd.read_csv(file_path)\n","else:\n","    print(\"파일을 찾을 수 없습니다. 경로를 확인해주세요.\")\n","    # 임시 빈 데이터프레임 생성 (에러 방지용)\n","    df = pd.DataFrame()\n","\n","# 센서 컬럼 정의\n","sensor_cols = [\n","    'BCl3 Flow', 'Cl2 Flow', 'RF Btm Pwr', 'RF Btm Rfl Pwr', 'Endpt A',\n","    'He Press', 'Pressure', 'RF Tuner', 'RF Load', 'RF Phase Err',\n","    'RF Pwr', 'RF Impedance', 'TCP Tuner', 'TCP Phase Err',\n","    'TCP Impedance', 'TCP Top Pwr', 'TCP Rfl Pwr', 'TCP Load', 'Vat Valve'\n","]\n","\n","# ==========================================\n","# 3. 데이터 전처리 함수\n","# ==========================================\n","\"\"\"\n","    Wafer_ID 별로 그룹화하여 슬라이딩 윈도우를 적용하는 함수\n","\n","    Args:\n","        df_target: 대상 데이터프레임\n","        wafer_col: Wafer ID 컬럼명\n","        sensor_cols: 센서 데이터 컬럼 리스트\n","        seq_len: 윈도우 크기\n","        scaler: 사용할 스케일러 (None이면 새로 생성)\n","        is_train: 학습 모드 여부 (True면 fit_transform, False면 transform)\n","\n","    Returns:\n","        X_all: (N, seq_len, n_features) 형태의 numpy 배열\n","        scaler: 학습/사용된 스케일러\n","\"\"\"\n","def create_sequences_per_wafer(df_target, wafer_col, sensor_cols, seq_len, scaler=None, is_train=True):\n","\n","    # 1. 스케일링 처리\n","    # (Wafer별로 따로 스케일링하면 Wafer 간의 상대적 크기 정보가 사라질 수 있으므로 전체 기준으로 합니다.)\n","    data_values = df_target[sensor_cols].values\n","\n","    if is_train:\n","        # 학습용: Scaler 생성 및 학습\n","        if scaler is None:\n","            scaler = MinMaxScaler()\n","        data_scaled = scaler.fit_transform(data_values)\n","    else:\n","        # 테스트용: 기존 Scaler 사용\n","        if scaler is None:\n","            raise ValueError(\"Test mode requires a fitted scaler.\")\n","        data_scaled = scaler.transform(data_values)\n","\n","    # 스케일링 된 데이터를 다시 DataFrame에 맵핑 (Wafer ID로 그룹핑하기 위해)\n","    df_scaled = pd.DataFrame(data_scaled, columns=sensor_cols, index=df_target.index)\n","    df_scaled[wafer_col] = df_target[wafer_col]\n","\n","    all_sequences = []\n","\n","    # 2. Wafer ID 별로 슬라이딩 윈도우 적용\n","    unique_wafers = df_scaled[wafer_col].unique()\n","\n","    for wafer in unique_wafers:\n","        # 특정 Wafer 데이터 추출\n","        wafer_data = df_scaled[df_scaled[wafer_col] == wafer][sensor_cols].values\n","\n","        # 데이터가 윈도우 크기보다 작으면 스킵\n","        if len(wafer_data) < seq_len:\n","            continue\n","\n","        # 슬라이딩 윈도우 생성\n","        for i in range(len(wafer_data) - seq_len + 1):\n","            all_sequences.append(wafer_data[i : i + seq_len])\n","\n","    if len(all_sequences) == 0:\n","        return np.array([]), scaler\n","\n","    return np.array(all_sequences), scaler\n","\n","# ==========================================\n","# 4. 데이터셋 구성 (실험별 루프)\n","# ==========================================\n","experiments = ['l29', 'l31', 'l33']\n","datasets = {}\n","\n","print(\"\\n--- Preprocessing Data (Per Wafer Logic) ---\")\n","\n","for exp_id in experiments:\n","    print(f\"\\nProcessing Experiment: {exp_id}\")\n","\n","    # 1. 해당 실험 데이터 추출\n","    exp_df = df[df['Wafer_ID'].str.contains(exp_id, case=False, na=False)]\n","\n","    if exp_df.empty:\n","        print(f\"No data for {exp_id}\")\n","        continue\n","\n","    # 2. Wafer ID 추출 및 분할 (Label 기준)\n","    # 정상 Wafer와 불량 Wafer의 ID 리스트를 확보\n","    normal_wafer_ids = exp_df[exp_df['Label'] == 'Normal']['Wafer_ID'].unique()\n","    fault_wafer_ids = exp_df[exp_df['Label'] == 'Fault']['Wafer_ID'].unique()\n","\n","    print(f\"  - Total Normal Wafers: {len(normal_wafer_ids)}\")\n","    print(f\"  - Total Fault Wafers: {len(fault_wafer_ids)}\")\n","\n","    # 정상 Wafer가 너무 적으면 스킵\n","    if len(normal_wafer_ids) < 4:\n","        print(\"  - Not enough normal wafers to split.\")\n","        continue\n","\n","    # 3. Train / Test Split (Wafer ID 기준)\n","    # 정상 Wafer 중 80%는 학습용, 20%는 테스트용\n","    n_train_wafers = int(len(normal_wafer_ids) * 0.8)\n","\n","    train_wafer_ids = normal_wafer_ids[:n_train_wafers]\n","    test_norm_wafer_ids = normal_wafer_ids[n_train_wafers:]\n","\n","    # ID를 기준으로 데이터프레임 필터링\n","    train_df = exp_df[exp_df['Wafer_ID'].isin(train_wafer_ids)]\n","    test_norm_df = exp_df[exp_df['Wafer_ID'].isin(test_norm_wafer_ids)]\n","    test_fault_df = exp_df[exp_df['Wafer_ID'].isin(fault_wafer_ids)]\n","\n","    # 4. 슬라이딩 윈도우 파라미터 설정\n","    SEQ_LEN = 10\n","\n","    # (1) Train Data: Fit & Transform\n","    # 여기서 만들어진 scaler를 반환받아 테스트셋에 적용합니다.\n","    X_train, scaler = create_sequences_per_wafer(\n","        train_df, 'Wafer_ID', sensor_cols, SEQ_LEN, scaler=None, is_train=True\n","    )\n","\n","    # (2) Test Normal Data: Transform Only\n","    X_test_normal, _ = create_sequences_per_wafer(\n","        test_norm_df, 'Wafer_ID', sensor_cols, SEQ_LEN, scaler=scaler, is_train=False     # 학습 데이터로 변환한 Scaler 적용\n","    )\n","\n","    # (3) Test Fault Data: Transform Only\n","    if not test_fault_df.empty:\n","        X_test_fault, _ = create_sequences_per_wafer(\n","            test_fault_df, 'Wafer_ID', sensor_cols, SEQ_LEN, scaler=scaler, is_train=False    # 학습 데이터로 변환한 Scaler 적용\n","        )\n","    else:\n","        X_test_fault = np.array([])\n","\n","    # 5. 결과 저장\n","    datasets[exp_id] = {\n","        'X_train': X_train,\n","        'X_test_norm': X_test_normal,\n","        'X_test_fault': X_test_fault,\n","        'scaler': scaler\n","    }\n","\n","    print(f\"  -> [{exp_id}] Result Shapes:\")\n","    print(f\"     X_train     : {X_train.shape}\")\n","    print(f\"     X_test_norm : {X_test_normal.shape}\")\n","    print(f\"     X_test_fault: {X_test_fault.shape}\")\n","\n","print(\"\\nData preprocessing completed.\")"],"metadata":{"id":"CmHwpq3jVovB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770703250670,"user_tz":-540,"elapsed":9929,"user":{"displayName":"이성재","userId":"12219853136685213654"}},"outputId":"2ce4f1cb-5c99-4a9c-b7e2-c76c3b5da264"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data from: /content/drive/MyDrive/ASK_2026_FDC/Dataset/MACHINE_Data.xlsx\n","\n","--- Preprocessing Data (Per Wafer Logic) ---\n","\n","Processing Experiment: l29\n","  - Total Normal Wafers: 34\n","  - Total Fault Wafers: 9\n","  -> [l29] Result Shapes:\n","     X_train     : (2546, 10, 19)\n","     X_test_norm : (634, 10, 19)\n","     X_test_fault: (832, 10, 19)\n","\n","Processing Experiment: l31\n","  - Total Normal Wafers: 37\n","  - Total Fault Wafers: 6\n","  -> [l31] Result Shapes:\n","     X_train     : (2589, 10, 19)\n","     X_test_norm : (722, 10, 19)\n","     X_test_fault: (488, 10, 19)\n","\n","Processing Experiment: l33\n","  - Total Normal Wafers: 37\n","  - Total Fault Wafers: 6\n","  -> [l33] Result Shapes:\n","     X_train     : (2607, 10, 19)\n","     X_test_norm : (706, 10, 19)\n","     X_test_fault: (550, 10, 19)\n","\n","Data preprocessing completed.\n"]}]},{"cell_type":"markdown","source":["## **전처리 과정 검토**"],"metadata":{"id":"NBe1qTHkBpVl"}},{"cell_type":"code","source":["def inspect_sliding_window_logic(df, experiment_id, wafer_idx=0, seq_len=10):\n","    print(f\"=== Sliding Window Verification for Experiment: {experiment_id} ===\")\n","\n","    # 1. 해당 실험의 특정 Wafer ID 하나 선택\n","    exp_df = df[df['Wafer_ID'].str.contains(experiment_id, case=False, na=False)]\n","    unique_wafers = exp_df['Wafer_ID'].unique()\n","\n","    if len(unique_wafers) == 0:\n","        print(\"해당 실험 데이터가 없습니다.\")\n","        return\n","\n","    target_wafer = unique_wafers[wafer_idx] # 첫 번째 Wafer 선택\n","    print(f\"Target Wafer ID: {target_wafer}\")\n","\n","    # 2. 원본 데이터(Raw) 추출\n","    # 전처리 때 사용한 센서 컬럼만 선택\n","    raw_data = exp_df[exp_df['Wafer_ID'] == target_wafer][sensor_cols].values\n","    raw_len = len(raw_data)\n","\n","    print(f\"Original Data Length (Rows): {raw_len}\")\n","    print(f\"Window Size (Seq_len): {seq_len}\")\n","\n","    # 3. 이론상 생성되어야 할 시퀀스 개수 계산\n","    # 공식: (원본 길이 - 윈도우 크기) + 1\n","    expected_sequences = raw_len - seq_len + 1\n","    print(f\"Expected Sequences: {raw_len} - {seq_len} + 1 = {expected_sequences}\")\n","\n","    # 4. 실제 슬라이딩 윈도우 수행 (검증용 로직)\n","    actual_sequences = []\n","    for i in range(expected_sequences):\n","        actual_sequences.append(raw_data[i : i + seq_len])\n","\n","    actual_sequences = np.array(actual_sequences)\n","    print(f\"Generated Sequences Shape: {actual_sequences.shape}\")\n","\n","    if expected_sequences == actual_sequences.shape[0]:\n","        print(\">> [PASS] 시퀀스 개수가 이론과 정확히 일치합니다.\")\n","    else:\n","        print(\">> [FAIL] 시퀀스 개수가 다릅니다!\")\n","\n","    print(\"\\n--- Data Content Check (First 2 Sequences) ---\")\n","    # 5. 데이터가 한 칸씩 밀렸는지 확인 (첫 번째 센서 기준)\n","    # 첫 번째 시퀀스 (Time 0 ~ 9)\n","    seq_0 = actual_sequences[0, :, 0] # 첫 번째 시퀀스의 첫 번째 센서 값들\n","    # 두 번째 시퀀스 (Time 1 ~ 10)\n","    seq_1 = actual_sequences[1, :, 0] # 두 번째 시퀀스의 첫 번째 센서 값들\n","\n","    print(f\"Seq 0 (Time 0~9) : {seq_0}\")\n","    print(f\"Seq 1 (Time 1~10): {seq_1}\")\n","\n","    # 비교: Seq 1의 앞부분(0~8)이 Seq 0의 뒷부분(1~9)과 같아야 함\n","    is_shifted_correctly = np.allclose(seq_0[1:], seq_1[:-1])\n","\n","    print(f\"\\nVerifying Overlap (Seq 0[1:] == Seq 1[:-1]): {is_shifted_correctly}\")\n","    if is_shifted_correctly:\n","        print(\">> [PASS] 데이터가 정확히 1 Time Step씩 슬라이딩 되었습니다.\")\n","    else:\n","        print(\">> [FAIL] 데이터 슬라이딩이 올바르지 않습니다.\")\n","\n","# 검증 실행 (l29 실험의 첫 번째 Wafer 확인)\n","inspect_sliding_window_logic(df, 'l29', wafer_idx=0, seq_len=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b_Xw4txASQke","executionInfo":{"status":"ok","timestamp":1770703250686,"user_tz":-540,"elapsed":15,"user":{"displayName":"이성재","userId":"12219853136685213654"}},"outputId":"63ef19f2-b067-456e-87cc-4c83e03a2b17"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Sliding Window Verification for Experiment: l29 ===\n","Target Wafer ID: l2901.txm\n","Original Data Length (Rows): 112\n","Window Size (Seq_len): 10\n","Expected Sequences: 112 - 10 + 1 = 103\n","Generated Sequences Shape: (103, 10, 19)\n",">> [PASS] 시퀀스 개수가 이론과 정확히 일치합니다.\n","\n","--- Data Content Check (First 2 Sequences) ---\n","Seq 0 (Time 0~9) : [751. 751. 751. 751. 751. 751. 751. 751. 751. 751.]\n","Seq 1 (Time 1~10): [751. 751. 751. 751. 751. 751. 751. 751. 751. 751.]\n","\n","Verifying Overlap (Seq 0[1:] == Seq 1[:-1]): True\n",">> [PASS] 데이터가 정확히 1 Time Step씩 슬라이딩 되었습니다.\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","def verify_sliding_window_random(df, experiment_id, wafer_idx=0, seq_len=10):\n","    print(f\"=== Random Sliding Window Verification for {experiment_id} ===\")\n","\n","    # 1. 데이터 준비 (이전과 동일)\n","    exp_df = df[df['Wafer_ID'].str.contains(experiment_id, case=False, na=False)]\n","    unique_wafers = exp_df['Wafer_ID'].unique()\n","\n","    if len(unique_wafers) == 0:\n","        print(\"데이터 없음\")\n","        return\n","\n","    target_wafer = unique_wafers[wafer_idx]\n","    # 원본 데이터 (numpy array)\n","    raw_data = exp_df[exp_df['Wafer_ID'] == target_wafer][sensor_cols].values\n","\n","    # 2. 슬라이딩 윈도우 생성\n","    sequences = []\n","    for i in range(len(raw_data) - seq_len + 1):\n","        sequences.append(raw_data[i : i + seq_len])\n","    sequences = np.array(sequences)\n","\n","    total_seq = sequences.shape[0]\n","    print(f\"Target Wafer: {target_wafer}\")\n","    print(f\"Total Generated Sequences: {total_seq}\")\n","\n","    # 3. 무작위 인덱스 선택 (마지막 인덱스는 다음 게 없으므로 제외)\n","    # 값이 변하는 것을 보기 위해 시도 횟수를 늘리거나 하지 않고, 순수 랜덤으로 뽑습니다.\n","    rand_idx = np.random.randint(0, total_seq - 1)\n","\n","    print(f\"\\n--- Checking Random Index: {rand_idx} vs {rand_idx+1} ---\")\n","\n","    # 두 개의 연속된 시퀀스 추출\n","    seq_A = sequences[rand_idx]      # 현재 시퀀스\n","    seq_B = sequences[rand_idx + 1]  # 다음 시퀀스 (1 Time step 뒤)\n","\n","    # 4. 비교를 위해 특정 센서 하나만 출력 (값이 좀 변하는 센서를 찾아서 출력하면 좋음)\n","    # 여기서는 6번째 센서(Pressure)나 10번째(RF Pwr) 등을 봅니다.\n","    target_sensor_idx = 6  # Pressure (예시)\n","    sensor_name = sensor_cols[target_sensor_idx]\n","\n","    val_A = seq_A[:, target_sensor_idx]\n","    val_B = seq_B[:, target_sensor_idx]\n","\n","    print(f\"Sensor: {sensor_name}\")\n","    print(f\"Seq {rand_idx:<3} (t={rand_idx}~{rand_idx+9})   : {np.round(val_A, 2)}\")\n","    print(f\"Seq {rand_idx+1:<3} (t={rand_idx+1}~{rand_idx+10}): {np.round(val_B, 2)}\")\n","\n","    # 5. 시각적 검증 가이드\n","    print(\"\\n[검증 가이드]\")\n","    print(f\"Seq {rand_idx}의 2번째 값({val_A[1]:.2f})부터 마지막 값까지가\")\n","    print(f\"Seq {rand_idx+1}의 1번째 값({val_B[0]:.2f})부터 9번째 값과 같아야 합니다.\")\n","\n","    # 6. 로직 검증\n","    # seq_A[1:] 과 seq_B[:-1] 이 같은지 확인\n","    is_match = np.allclose(seq_A[1:], seq_B[:-1])\n","\n","    print(f\"\\n>> Overlap Check Result: {is_match}\")\n","    if is_match:\n","        print(\">> [SUCCESS] 데이터가 정확하게 한 칸씩 밀려있습니다.\")\n","    else:\n","        print(\">> [FAIL] 데이터 불일치 발생!\")\n","\n","# 실행\n","verify_sliding_window_random(df, 'l29', wafer_idx=0, seq_len=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ed794o-YTMxp","executionInfo":{"status":"ok","timestamp":1770703250735,"user_tz":-540,"elapsed":27,"user":{"displayName":"이성재","userId":"12219853136685213654"}},"outputId":"61e494e6-f0c2-43c8-a68f-8ba3c1bdf9cc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["=== Random Sliding Window Verification for l29 ===\n","Target Wafer: l2901.txm\n","Total Generated Sequences: 103\n","\n","--- Checking Random Index: 87 vs 88 ---\n","Sensor: Pressure\n","Seq 87  (t=87~96)   : [1185. 1186. 1183. 1185. 1186. 1185. 1183. 1185. 1184. 1187.]\n","Seq 88  (t=88~97): [1186. 1183. 1185. 1186. 1185. 1183. 1185. 1184. 1187. 1184.]\n","\n","[검증 가이드]\n","Seq 87의 2번째 값(1186.00)부터 마지막 값까지가\n","Seq 88의 1번째 값(1186.00)부터 9번째 값과 같아야 합니다.\n","\n",">> Overlap Check Result: True\n",">> [SUCCESS] 데이터가 정확하게 한 칸씩 밀려있습니다.\n"]}]},{"cell_type":"code","source":["def verify_wafer_aggregation(df, datasets, experiments, seq_len=10):\n","    print(\"=\"*60)\n","    print(\"      데이터셋 구성 무결성 검증 (Wafer Aggregation Check)\")\n","    print(\"=\"*60)\n","\n","    for exp_id in experiments:\n","        print(f\"\\nTarget Experiment: [{exp_id}]\")\n","\n","        # 1. 원본 데이터에서 Wafer ID 리스트 및 분할 로직 재현\n","        exp_df = df[df['Wafer_ID'].str.contains(exp_id, case=False, na=False)]\n","        if exp_df.empty: continue\n","\n","        # Normal / Fault 분류\n","        normal_wafer_ids = exp_df[exp_df['Label'] == 'Normal']['Wafer_ID'].unique()\n","        fault_wafer_ids = exp_df[exp_df['Label'] == 'Fault']['Wafer_ID'].unique()\n","\n","        # Train / Test Split (80:20) 로직 재현\n","        n_train = int(len(normal_wafer_ids) * 0.8)\n","        train_ids = normal_wafer_ids[:n_train]\n","        test_norm_ids = normal_wafer_ids[n_train:]\n","        test_fault_ids = fault_wafer_ids # 전체 사용\n","\n","        # 검증 대상 맵핑\n","        targets = [\n","            ('X_train', train_ids),\n","            ('X_test_norm', test_norm_ids),\n","            ('X_test_fault', test_fault_ids)\n","        ]\n","\n","        for key, wafer_ids in targets:\n","            # 저장된 실제 데이터 모양\n","            stored_data = datasets[exp_id][key]\n","            actual_count = stored_data.shape[0] if len(stored_data) > 0 else 0\n","\n","            # 2. Wafer ID 별 기대 시퀀스 개수 계산\n","            expected_count = 0\n","            wafer_details = [] # 상세 로그용\n","\n","            for wafer in wafer_ids:\n","                # 해당 Wafer의 원본 데이터 길이\n","                raw_len = len(exp_df[exp_df['Wafer_ID'] == wafer])\n","\n","                # 시퀀스 생성 가능 개수 계산\n","                if raw_len >= seq_len:\n","                    seq_count = raw_len - seq_len + 1\n","                    expected_count += seq_count\n","                    wafer_details.append(f\"{wafer}({seq_count})\")\n","                else:\n","                    wafer_details.append(f\"{wafer}(Skip:TooShort)\")\n","\n","            # 3. 비교 및 결과 출력\n","            print(f\"  [{key}] Check:\")\n","            print(f\"    - Included Wafers ({len(wafer_ids)}): {', '.join(wafer_details[:5])} ...\") # 5개만 예시 출력\n","            print(f\"    - Expected Sum : {expected_count}\")\n","            print(f\"    - Actual Shape : {actual_count}\")\n","\n","            if expected_count == actual_count:\n","                print(f\"    >> [PASS] {key} 데이터가 누락 없이 정확하게 합쳐졌습니다.\")\n","            else:\n","                print(f\"    >> [FAIL] 개수 불일치! (Diff: {actual_count - expected_count})\")\n","\n","    print(\"\\nVerification Completed.\")\n","\n","# 검증 실행\n","verify_wafer_aggregation(df, datasets, experiments, seq_len=10)"],"metadata":{"id":"dX8hvwDlUBiu","executionInfo":{"status":"ok","timestamp":1770703250975,"user_tz":-540,"elapsed":236,"user":{"displayName":"이성재","userId":"12219853136685213654"}},"outputId":"03f52c4a-f9ac-4161-e883-5b726acc68f1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","      데이터셋 구성 무결성 검증 (Wafer Aggregation Check)\n","============================================================\n","\n","Target Experiment: [l29]\n","  [X_train] Check:\n","    - Included Wafers (27): l2901.txm(103), l2902.txm(98), l2903.txm(97), l2904.txm(95), l2905.txm(96) ...\n","    - Expected Sum : 2546\n","    - Actual Shape : 2546\n","    >> [PASS] X_train 데이터가 누락 없이 정확하게 합쳐졌습니다.\n","  [X_test_norm] Check:\n","    - Included Wafers (7): l2932.txm(91), l2933.txm(91), l2934.txm(93), l2935.txm(92), l2941.txm(89) ...\n","    - Expected Sum : 634\n","    - Actual Shape : 634\n","    >> [PASS] X_test_norm 데이터가 누락 없이 정확하게 합쳐졌습니다.\n","  [X_test_fault] Check:\n","    - Included Wafers (9): l2915.txm(94), l2916.txm(97), l2917.txm(93), l2918.txm(84), l2936.txm(89) ...\n","    - Expected Sum : 832\n","    - Actual Shape : 832\n","    >> [PASS] X_test_fault 데이터가 누락 없이 정확하게 합쳐졌습니다.\n","\n","Target Experiment: [l31]\n","  [X_train] Check:\n","    - Included Wafers (29): l3101.txm(99), l3102.txm(96), l3103.txm(97), l3104.txm(94), l3105.txm(95) ...\n","    - Expected Sum : 2589\n","    - Actual Shape : 2589\n","    >> [PASS] X_train 데이터가 누락 없이 정확하게 합쳐졌습니다.\n","  [X_test_norm] Check:\n","    - Included Wafers (8): l3133.txm(89), l3134.txm(92), l3135.txm(91), l3136.txm(89), l3137.txm(90) ...\n","    - Expected Sum : 722\n","    - Actual Shape : 722\n","    >> [PASS] X_test_norm 데이터가 누락 없이 정확하게 합쳐졌습니다.\n","  [X_test_fault] Check:\n","    - Included Wafers (6): l3120.txm(91), l3121.txm(86), l3122.txm(47), l3141.txm(90), l3142.txm(83) ...\n","    - Expected Sum : 488\n","    - Actual Shape : 488\n","    >> [PASS] X_test_fault 데이터가 누락 없이 정확하게 합쳐졌습니다.\n","\n","Target Experiment: [l33]\n","  [X_train] Check:\n","    - Included Wafers (29): l3301.txm(91), l3302.txm(91), l3303.txm(92), l3304.txm(94), l3305.txm(91) ...\n","    - Expected Sum : 2607\n","    - Actual Shape : 2607\n","    >> [PASS] X_train 데이터가 누락 없이 정확하게 합쳐졌습니다.\n","  [X_test_norm] Check:\n","    - Included Wafers (8): l3333.txm(89), l3334.txm(89), l3335.txm(89), l3336.txm(86), l3337.txm(90) ...\n","    - Expected Sum : 706\n","    - Actual Shape : 706\n","    >> [PASS] X_test_norm 데이터가 누락 없이 정확하게 합쳐졌습니다.\n","  [X_test_fault] Check:\n","    - Included Wafers (6): l3318.txm(91), l3319.txm(99), l3320.txm(93), l3339.txm(93), l3340.txm(86) ...\n","    - Expected Sum : 550\n","    - Actual Shape : 550\n","    >> [PASS] X_test_fault 데이터가 누락 없이 정확하게 합쳐졌습니다.\n","\n","Verification Completed.\n"]}]}]}