{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXAotAeCCXfrb3mDAvkXFC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **1. ÎìúÎùºÏù¥Î∏å Ïó∞Í≤∞**"],"metadata":{"id":"1MYsT1SY0L0C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRnMS0-7z_HP"},"outputs":[],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## **2. ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï, Îç∞Ïù¥ÌÑ∞ Î°úÎìú, Îç∞Ïù¥ÌÑ∞ÏÖã Î∂ÑÎ¶¨**\n","\n","- Î™®Îì† Ïã§ÌóòÏùÑ ÌÜµÌï©ÌïòÏó¨ Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨ÏÑ±"],"metadata":{"id":"PFm-1Ntz0ORG"}},{"cell_type":"code","source":["# ==========================================\n","# 1. ÎùºÏù¥Î∏åÎü¨Î¶¨ Î∞è ÌôòÍ≤Ω ÏÑ§Ï†ï\n","# ==========================================\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix\n","import os\n","import warnings\n","\n","warnings.filterwarnings('ignore')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# ==========================================\n","# 2. ÌÜµÌï© Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ (Unified Dataset)\n","# ==========================================\n","file_path = \"/content/drive/MyDrive/ASK_2026_FDC/Dataset/MACHINE_Data.xlsx\"\n","if os.path.exists(file_path):\n","    df = pd.read_excel(file_path) if file_path.endswith('.xlsx') else pd.read_csv(file_path)\n","else:\n","    df = pd.DataFrame()\n","\n","sensor_cols = [\n","    'BCl3 Flow', 'Cl2 Flow', 'RF Btm Pwr', 'RF Btm Rfl Pwr', 'Endpt A',\n","    'He Press', 'Pressure', 'RF Tuner', 'RF Load', 'RF Phase Err',\n","    'RF Pwr', 'RF Impedance', 'TCP Tuner', 'TCP Phase Err',\n","    'TCP Impedance', 'TCP Top Pwr', 'TCP Rfl Pwr', 'TCP Load', 'Vat Valve'\n","]\n","\n","def create_sequences_with_ids(df_target, wafer_col, sensor_cols, seq_len, scaler=None, is_train=True):\n","    data_values = df_target[sensor_cols].values\n","    if is_train:\n","        if scaler is None: scaler = MinMaxScaler()\n","        data_scaled = scaler.fit_transform(data_values)\n","    else:\n","        data_scaled = scaler.transform(data_values)\n","\n","    df_scaled = pd.DataFrame(data_scaled, columns=sensor_cols, index=df_target.index)\n","    df_scaled[wafer_col] = df_target[wafer_col].values\n","\n","    all_sequences, all_wafer_ids = [], []\n","    for wafer in df_scaled[wafer_col].unique():\n","        wafer_data = df_scaled[df_scaled[wafer_col] == wafer][sensor_cols].values\n","        if len(wafer_data) < seq_len: continue\n","        for i in range(len(wafer_data) - seq_len + 1):\n","            all_sequences.append(wafer_data[i : i + seq_len])\n","            all_wafer_ids.append(wafer)\n","\n","    if len(all_sequences) == 0: return np.array([]), np.array([]), scaler\n","    return np.array(all_sequences), np.array(all_wafer_ids), scaler\n","\n","\n","\n","# --- Îç∞Ïù¥ÌÑ∞ ÌÜµÌï© Î∞è Î∂ÑÌï† ---\n","datasets = {}\n","target_experiments = ['l29', 'l31', 'l33']\n","SEQ_LEN = 32\n","TRAIN_RATIO = 0.7\n","\n","print(f\"üöÄ Creating Unified Dataset from: {target_experiments}\")\n","\n","# ÌÜµÌï© Îç∞Ïù¥ÌÑ∞ ÌïÑÌÑ∞ÎßÅ\n","combined_mask = df['Wafer_ID'].str.contains('|'.join(target_experiments), case=False, na=False)\n","combined_df = df[combined_mask]\n","\n","# ID ÏÖîÌîå Î∞è Î∂ÑÌï†\n","all_normal_ids = combined_df[combined_df['Label'] == 'Normal']['Wafer_ID'].unique()\n","all_fault_ids = combined_df[combined_df['Label'] == 'Fault']['Wafer_ID'].unique()\n","\n","np.random.seed(42)\n","np.random.shuffle(all_normal_ids)\n","\n","n_train = int(len(all_normal_ids) * TRAIN_RATIO)\n","train_ids = all_normal_ids[:n_train]\n","test_norm_ids = all_normal_ids[n_train:]\n","\n","# Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ Î∂ÑÌï†\n","df_train = combined_df[combined_df['Wafer_ID'].isin(train_ids)]\n","df_test_norm = combined_df[combined_df['Wafer_ID'].isin(test_norm_ids)]\n","df_test_fault = combined_df[combined_df['Wafer_ID'].isin(all_fault_ids)]\n","\n","# ÏãúÌÄÄÏä§ ÏÉùÏÑ±\n","X_train, ids_train, global_scaler = create_sequences_with_ids(df_train, 'Wafer_ID', sensor_cols, SEQ_LEN, scaler=None, is_train=True)\n","X_test_norm, ids_test_norm, _ = create_sequences_with_ids(df_test_norm, 'Wafer_ID', sensor_cols, SEQ_LEN, scaler=global_scaler, is_train=False)\n","X_test_fault, ids_test_fault, _ = create_sequences_with_ids(df_test_fault, 'Wafer_ID', sensor_cols, SEQ_LEN, scaler=global_scaler, is_train=False)\n","\n","# ÏÇ¨Ïö©ÏûêÍ∞Ä Ï†úÍ≥µÌïú get_data_loaders Ìï®ÏàòÍ∞Ä ÏûëÎèôÌïòÎèÑÎ°ù ÎîïÏÖîÎÑàÎ¶¨Ïóê Ï†ÄÏû•\n","datasets['Unified'] = {\n","    'X_train': X_train,\n","    'X_test_norm': X_test_norm,\n","    'ids_test_norm': ids_test_norm,\n","    'X_test_fault': X_test_fault,\n","    'ids_test_fault': ids_test_fault\n","}\n","print(\"‚úÖ Unified Dataset Prepared.\")"],"metadata":{"id":"CuGxMG5A0GmD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **3. Ìï®Ïàò Ï†ïÏùò**"],"metadata":{"id":"bQLNphch0aqP"}},{"cell_type":"code","source":["# ==========================================\n","# 3. Ïú†Ìã∏Î¶¨Ìã∞ Ìï®Ïàò (Îç∞Ïù¥ÌÑ∞ Î°úÎìú, ÏßëÍ≥Ñ, ÏãúÍ∞ÅÌôî)\n","# ==========================================\n","def get_data_loaders(exp_id, datasets_dict, batch_size=32):\n","    print(f\"\\nüìä [Data Setup] Experiment: {exp_id}\")\n","    data = datasets_dict[exp_id]\n","\n","    # Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú\n","    X_train = data['X_train']\n","    X_test_norm = data['X_test_norm']\n","    ids_test_norm = data['ids_test_norm']\n","    X_test_fault = data['X_test_fault']\n","    ids_test_fault = data['ids_test_fault']\n","\n","    # Tensor Î≥ÄÌôò\n","    train_tensor = torch.FloatTensor(X_train).to(device)\n","    test_norm_tensor = torch.FloatTensor(X_test_norm).to(device)\n","\n","    if len(X_test_fault) > 0:\n","        test_fault_tensor = torch.FloatTensor(X_test_fault).to(device)\n","    else:\n","        test_fault_tensor = torch.FloatTensor([]).to(device)\n","\n","    # DataLoader (Train only)\n","    train_loader = DataLoader(TensorDataset(train_tensor), batch_size=batch_size, shuffle=True)\n","\n","    return train_loader, (test_norm_tensor, ids_test_norm), (test_fault_tensor, ids_test_fault)\n","\n","def aggregate_wafer_scores(window_scores, wafer_ids, method='max'):\n","    # DataFrameÌïëÌïòÏó¨ GroupBy Ïó∞ÏÇ∞\n","    df_temp = pd.DataFrame({'Wafer_ID': wafer_ids, 'Score': window_scores})\n","\n","    if method == 'max':\n","        grouped = df_temp.groupby('Wafer_ID')['Score'].max()\n","    else:\n","        grouped = df_temp.groupby('Wafer_ID')['Score'].mean()\n","\n","    return grouped.index.values, grouped.values\n","\n","def visualize_results(model_name, exp_id, scores, labels, threshold):\n","    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n","    plt.suptitle(f\"[{exp_id}] {model_name} Performance (Wafer-Level)\", fontsize=16, fontweight='bold')\n","\n","    # Confusion Matrix\n","    preds = (scores > threshold).astype(int)\n","    cm = confusion_matrix(labels, preds)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0],\n","                xticklabels=['Normal', 'Fault'], yticklabels=['Normal', 'Fault'])\n","    axes[0].set_title(\"Confusion Matrix\")\n","\n","    # Scatter Plot (Wafer Scores)\n","    normal_idx = np.where(labels == 0)[0]\n","    fault_idx = np.where(labels == 1)[0]\n","\n","    axes[1].scatter(normal_idx, scores[normal_idx], color='blue', label='Normal', alpha=0.6, s=20)\n","    axes[1].scatter(fault_idx, scores[fault_idx], color='red', label='Fault', alpha=0.6, s=20)\n","    axes[1].axhline(y=threshold, color='green', linestyle='--', label='Threshold')\n","    axes[1].set_title(\"Wafer Anomaly Scores\")\n","    axes[1].legend()\n","\n","    # ROC Curve\n","    fpr, tpr, _ = roc_curve(labels, scores)\n","    roc_auc = auc(fpr, tpr)\n","    axes[2].plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.4f}')\n","    axes[2].plot([0, 1], [0, 1], color='navy', linestyle='--')\n","    axes[2].set_title(\"ROC Curve\")\n","    axes[2].legend()\n","\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","    plt.show()\n","\n","def evaluate_performance(model_name, exp_id, scores, labels):\n","    precision, recall, thresholds = precision_recall_curve(labels, scores)\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        f1_scores = 2 * recall * precision / (recall + precision)\n","    f1_scores = np.nan_to_num(f1_scores)\n","\n","    best_idx = np.argmax(f1_scores)\n","    best_f1 = f1_scores[best_idx]\n","    best_thresh = thresholds[best_idx]\n","\n","    fpr, tpr, _ = roc_curve(labels, scores)\n","    roc_auc = auc(fpr, tpr)\n","\n","    print(f\"\\nüìå [{model_name} - {exp_id}] Wafer-Level Summary\")\n","    print(f\"   - AUROC         : {roc_auc:.4f}\")\n","    print(f\"   - Best F1-Score : {best_f1:.4f}\")\n","    print(f\"   - Best Threshold: {best_thresh:.6f}\")\n","\n","    visualize_results(model_name, exp_id, scores, labels, best_thresh)\n","    return roc_auc, best_f1"],"metadata":{"id":"EI-EaAH30JBH"},"execution_count":null,"outputs":[]}]}