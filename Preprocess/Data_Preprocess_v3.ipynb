{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMGeVV4lO0TT0B2mz+e0UdX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **1. ë“œë¼ì´ë¸Œ ì—°ê²°**"],"metadata":{"id":"1MYsT1SY0L0C"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rRnMS0-7z_HP"},"outputs":[],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## **2. íŒŒë¼ë¯¸í„° ì„¤ì •, ë°ì´í„° ë¡œë“œ, ë°ì´í„°ì…‹ ë¶„ë¦¬**\n","\n","- ì‹¤í—˜ ë³„ë¡œ ë‚˜ëˆ„ì–´ì„œ ë°ì´í„°ì…‹ êµ¬ì„±"],"metadata":{"id":"PFm-1Ntz0ORG"}},{"cell_type":"code","source":["# ==========================================\n","# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í™˜ê²½ ì„¤ì • (í•„ìˆ˜)\n","# ==========================================\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, f1_score\n","import pandas as pd\n","import numpy as np\n","import os\n","from sklearn.preprocessing import MinMaxScaler\n","import warnings\n","\n","\n","# ==========================================\n","# 2. ë°ì´í„° ë¡œë“œ\n","# ==========================================\n","file_path = \"/content/drive/MyDrive/ASK_2026_FDC/Dataset/MACHINE_Data.xlsx\"\n","\n","if os.path.exists(file_path):\n","    print(f\"Loading data from: {file_path}\")\n","    if file_path.endswith('.xlsx'):\n","        df = pd.read_excel(file_path)\n","    else:\n","        df = pd.read_csv(file_path)\n","else:\n","    print(\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n","    df = pd.DataFrame()\n","\n","# ì„¼ì„œ ì»¬ëŸ¼ ì •ì˜\n","sensor_cols = [\n","    'BCl3 Flow', 'Cl2 Flow', 'RF Btm Pwr', 'RF Btm Rfl Pwr', 'Endpt A',\n","    'He Press', 'Pressure', 'RF Tuner', 'RF Load', 'RF Phase Err',\n","    'RF Pwr', 'RF Impedance', 'TCP Tuner', 'TCP Phase Err',\n","    'TCP Impedance', 'TCP Top Pwr', 'TCP Rfl Pwr', 'TCP Load', 'Vat Valve'\n","]\n","\n","# ==========================================\n","# 3. ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜\n","# ==========================================\n","\"\"\"\n","    Wafer_ID ë³„ë¡œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¥¼ ì ìš©í•˜ê³ ,\n","    ê° ìœˆë„ìš°ê°€ ì–´ë–¤ Waferì— ì†í•˜ëŠ”ì§€ ID ë¦¬ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë°˜í™˜í•©ë‹ˆë‹¤.\n","\"\"\"\n","def create_sequences_with_ids(df_target, wafer_col, sensor_cols, seq_len, scaler=None, is_train=True):\n","\n","    # 1. ë°ì´í„° ì¶”ì¶œ\n","    data_values = df_target[sensor_cols].values\n","\n","    # 2. ìŠ¤ì¼€ì¼ë§ (Train í†µê³„ë¡œë§Œ Scale)\n","    if is_train:\n","        if scaler is None:\n","            scaler = MinMaxScaler()\n","        data_scaled = scaler.fit_transform(data_values)\n","    else:\n","        if scaler is None:\n","            raise ValueError(\"Test mode requires a fitted scaler from training data.\")\n","        data_scaled = scaler.transform(data_values)\n","\n","    # ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„°ë¥¼ ë‹¤ì‹œ DataFrameìœ¼ë¡œ ë§¤í•‘ (ID ê·¸ë£¹í•‘ ìš©ë„)\n","    df_scaled = pd.DataFrame(data_scaled, columns=sensor_cols, index=df_target.index)\n","    df_scaled[wafer_col] = df_target[wafer_col].values\n","\n","    all_sequences = []\n","    all_wafer_ids = [] # [NEW] ê° ìœˆë„ìš°ì˜ ì†ŒìŠ¤ Wafer IDë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n","\n","    unique_wafers = df_scaled[wafer_col].unique()\n","\n","    for wafer in unique_wafers:\n","        # íŠ¹ì • Wafer ë°ì´í„° ì¶”ì¶œ\n","        wafer_data = df_scaled[df_scaled[wafer_col] == wafer][sensor_cols].values\n","\n","        # ë°ì´í„° ê¸¸ì´ê°€ ìœˆë„ìš°ë³´ë‹¤ ì‘ìœ¼ë©´ ìŠ¤í‚µ\n","        if len(wafer_data) < seq_len:\n","            continue\n","\n","        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìƒì„±\n","        for i in range(len(wafer_data) - seq_len + 1):\n","            window = wafer_data[i : i + seq_len]\n","\n","            all_sequences.append(window)\n","            all_wafer_ids.append(wafer) # [NEW] í˜„ì¬ ìœˆë„ìš°ì˜ Wafer ID ì €ì¥\n","\n","    if len(all_sequences) == 0:\n","        return np.array([]), np.array([]), scaler\n","\n","    return np.array(all_sequences), np.array(all_wafer_ids), scaler\n","\n","# ==========================================\n","# 4. ë°ì´í„°ì…‹ êµ¬ì„± ë° ì €ì¥\n","# ==========================================\n","experiments = ['l29', 'l31', 'l33']\n","datasets = {}\n","SEQ_LEN = 32\n","\n","# í•™ìŠµ ë°ì´í„° ë¹„ìœ¨ ì„¤ì •\n","TRAIN_RATIO = 0.6\n","\n","print(f\"\\n--- Preprocessing Data (Train Ratio: {TRAIN_RATIO*100}%) ---\")\n","\n","for exp_id in experiments:\n","    print(f\"\\nProcessing Experiment: {exp_id}\")\n","\n","    # 1. ì‹¤í—˜ ë°ì´í„° í•„í„°ë§\n","    exp_df = df[df['Wafer_ID'].str.contains(exp_id, case=False, na=False)]\n","    if exp_df.empty:\n","        continue\n","\n","    # 2. Train / Test Split (Wafer ID ê¸°ì¤€)\n","    normal_wafer_ids = exp_df[exp_df['Label'] == 'Normal']['Wafer_ID'].unique()\n","    fault_wafer_ids = exp_df[exp_df['Label'] == 'Fault']['Wafer_ID'].unique()\n","\n","    # [ìˆ˜ì •] ë¹„ìœ¨ ì ìš© (Normal Waferë§Œ ë¶„í• )\n","    n_train = int(len(normal_wafer_ids) * TRAIN_RATIO)\n","\n","    train_ids = normal_wafer_ids[:n_train]\n","    test_norm_ids = normal_wafer_ids[n_train:]\n","\n","    # ID ê¸°ë°˜ ë°ì´í„°í”„ë ˆì„ ë¶„í• \n","    train_df = exp_df[exp_df['Wafer_ID'].isin(train_ids)]\n","    test_norm_df = exp_df[exp_df['Wafer_ID'].isin(test_norm_ids)]\n","    test_fault_df = exp_df[exp_df['Wafer_ID'].isin(fault_wafer_ids)]\n","\n","    print(f\"  - Total Normal: {len(normal_wafer_ids)}\")\n","    print(f\"  -> Train Normal : {len(train_ids)} ({TRAIN_RATIO*100:.0f}%)\")\n","    print(f\"  -> Test Normal  : {len(test_norm_ids)} ({(1-TRAIN_RATIO)*100:.0f}%)\")\n","    print(f\"  -> Test Fault   : {len(fault_wafer_ids)} (100%)\")\n","\n","    # 3. ì‹œí€€ìŠ¤ ìƒì„± (X, Wafer_ID ë°˜í™˜)\n","    # (1) Train: Scaler í•™ìŠµ (Fit)\n","    X_train, y_train_ids, scaler = create_sequences_with_ids(\n","        train_df, 'Wafer_ID', sensor_cols, SEQ_LEN, scaler=None, is_train=True\n","    )\n","\n","    # (2) Test Normal: Scaler ì ìš© (Transform)\n","    X_test_norm, y_test_norm_ids, _ = create_sequences_with_ids(\n","        test_norm_df, 'Wafer_ID', sensor_cols, SEQ_LEN, scaler=scaler, is_train=False\n","    )\n","\n","    # (3) Test Fault: Scaler ì ìš© (Transform)\n","    if not test_fault_df.empty:\n","        X_test_fault, y_test_fault_ids, _ = create_sequences_with_ids(\n","            test_fault_df, 'Wafer_ID', sensor_cols, SEQ_LEN, scaler=scaler, is_train=False\n","        )\n","    else:\n","        X_test_fault, y_test_fault_ids = np.array([]), np.array([])\n","\n","    # 4. Dictionaryì— ì €ì¥\n","    datasets[exp_id] = {\n","        'X_train': X_train,\n","        'X_test_norm': X_test_norm,\n","        'X_test_fault': X_test_fault,\n","        'ids_train': y_train_ids,\n","        'ids_test_norm': y_test_norm_ids,\n","        'ids_test_fault': y_test_fault_ids,\n","        'scaler': scaler\n","    }\n","\n","print(\"\\nâœ… Data preprocessing with new ratio completed.\")"],"metadata":{"id":"CuGxMG5A0GmD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **3. í•¨ìˆ˜ ì •ì˜**"],"metadata":{"id":"bQLNphch0aqP"}},{"cell_type":"code","source":["# ==========================================\n","# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ë°ì´í„° ë¡œë“œ, ì§‘ê³„, ì‹œê°í™”)\n","# ==========================================\n","def get_data_loaders(exp_id, datasets_dict, batch_size=32):\n","    print(f\"\\nğŸ“Š [Data Setup] Experiment: {exp_id}\")\n","    data = datasets_dict[exp_id]\n","\n","    # ë°ì´í„° ì¶”ì¶œ\n","    X_train = data['X_train']\n","    X_test_norm = data['X_test_norm']\n","    ids_test_norm = data['ids_test_norm']\n","    X_test_fault = data['X_test_fault']\n","    ids_test_fault = data['ids_test_fault']\n","\n","    # Tensor ë³€í™˜\n","    train_tensor = torch.FloatTensor(X_train).to(device)\n","    test_norm_tensor = torch.FloatTensor(X_test_norm).to(device)\n","\n","    if len(X_test_fault) > 0:\n","        test_fault_tensor = torch.FloatTensor(X_test_fault).to(device)\n","    else:\n","        test_fault_tensor = torch.FloatTensor([]).to(device)\n","\n","    # DataLoader (Train only)\n","    train_loader = DataLoader(TensorDataset(train_tensor), batch_size=batch_size, shuffle=True)\n","\n","    return train_loader, (test_norm_tensor, ids_test_norm), (test_fault_tensor, ids_test_fault)\n","\n","def aggregate_wafer_scores(window_scores, wafer_ids, method='max'):\n","    # DataFrameí•‘í•˜ì—¬ GroupBy ì—°ì‚°\n","    df_temp = pd.DataFrame({'Wafer_ID': wafer_ids, 'Score': window_scores})\n","\n","    if method == 'max':\n","        grouped = df_temp.groupby('Wafer_ID')['Score'].max()\n","    else:\n","        grouped = df_temp.groupby('Wafer_ID')['Score'].mean()\n","\n","    return grouped.index.values, grouped.values\n","\n","def visualize_results(model_name, exp_id, scores, labels, threshold):\n","    fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n","    plt.suptitle(f\"[{exp_id}] {model_name} Performance (Wafer-Level)\", fontsize=16, fontweight='bold')\n","\n","    # Confusion Matrix\n","    preds = (scores > threshold).astype(int)\n","    cm = confusion_matrix(labels, preds)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0],\n","                xticklabels=['Normal', 'Fault'], yticklabels=['Normal', 'Fault'])\n","    axes[0].set_title(\"Confusion Matrix\")\n","\n","    # Scatter Plot (Wafer Scores)\n","    normal_idx = np.where(labels == 0)[0]\n","    fault_idx = np.where(labels == 1)[0]\n","\n","    axes[1].scatter(normal_idx, scores[normal_idx], color='blue', label='Normal', alpha=0.6, s=20)\n","    axes[1].scatter(fault_idx, scores[fault_idx], color='red', label='Fault', alpha=0.6, s=20)\n","    axes[1].axhline(y=threshold, color='green', linestyle='--', label='Threshold')\n","    axes[1].set_title(\"Wafer Anomaly Scores\")\n","    axes[1].legend()\n","\n","    # ROC Curve\n","    fpr, tpr, _ = roc_curve(labels, scores)\n","    roc_auc = auc(fpr, tpr)\n","    axes[2].plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.4f}')\n","    axes[2].plot([0, 1], [0, 1], color='navy', linestyle='--')\n","    axes[2].set_title(\"ROC Curve\")\n","    axes[2].legend()\n","\n","    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","    plt.show()\n","\n","def evaluate_performance(model_name, exp_id, scores, labels):\n","    precision, recall, thresholds = precision_recall_curve(labels, scores)\n","    with np.errstate(divide='ignore', invalid='ignore'):\n","        f1_scores = 2 * recall * precision / (recall + precision)\n","    f1_scores = np.nan_to_num(f1_scores)\n","\n","    best_idx = np.argmax(f1_scores)\n","    best_f1 = f1_scores[best_idx]\n","    best_thresh = thresholds[best_idx]\n","\n","    fpr, tpr, _ = roc_curve(labels, scores)\n","    roc_auc = auc(fpr, tpr)\n","\n","    print(f\"\\nğŸ“Œ [{model_name} - {exp_id}] Wafer-Level Summary\")\n","    print(f\"   - AUROC         : {roc_auc:.4f}\")\n","    print(f\"   - Best F1-Score : {best_f1:.4f}\")\n","    print(f\"   - Best Threshold: {best_thresh:.6f}\")\n","\n","    visualize_results(model_name, exp_id, scores, labels, best_thresh)\n","    return roc_auc, best_f1"],"metadata":{"id":"EI-EaAH30JBH"},"execution_count":null,"outputs":[]}]}