# 🥇 ASK2026 : 딥러닝 모델 기반 장비 이상 유무 탐지 (Fault Detection & Classification)

주제 : 딥러닝 모델 기반 장비 이상 유무 탐지
- 저자 : 이성재, 용규순, 최현준, 류병석, 김영균


## 1️⃣ 데이터셋
- LAM 9600 Metal Etch Data


## Our records, footprint
[2026-01-12]
연구 주제/목적 구체화
- SMT2020 데이터셋을 사용해서 Queue time 최적화를 통한 수율/생산성 향상
- SMT2020은 최신이자 검증된 데이터셋으로 다양한 Fab 공정 데이터를 모두 포함한다


방향성
- 선행연구에서 사용한 모델과 한계를 찾고 더 나은 방법론을 스크리닝
- 선행연구에서 SMT2020 데이터를 어떻게 Queue time 최적화에 사용했는지 학습
- SMT2020 2번 데이터셋 (연구개발 단계 제품, 다품종 소량생산) 사용으로 잠정 결정


논문작업
- Introduction: 공부한 내용을 바탕으로 내용을 기재하고 Reference까지 찾기


[2026-01-19]
연구 주제 변경
- SMT 2020 데이터셋의 선행 연구에서 시뮬레이션 작업이 필수적으로 요구되었으며 1달 남짓 남게된 시점에서 너무 무리한 작업이라고 판단되어 연구 주제를 변경함
- 이로 인하여 기존 데이터셋을 포함하여 조사하였고 그 중에 LAM 9600 Metal Etch Data를 선정하여 연구 주제를 정하였음
- 새롭게 정한 연구 주제는 딥러닝 모델 기반 장비 이상 유무 탐지로 정하였다.

작업 
- 논문 틀 잡기 (이성재)
- 선행 연구 조사
- 데이터셋 공부 (LAM 9600 Metal Etch Data)
- 모델 선정
- 훈련 코드 작성

업무 효율 개선
- 작업 진행마다 보고
- 어려운 부분이나 진행이 막힌 부분이 있다면 바로 카톡으로 소통


[2026-01-26]

논문 방향성 수립
- LAM 9600 데이터셋을 기반으로 다양한 딥러닝 모델을 적용하여 각 모델의 성능과 경량화를 기준으로 어떤 모델이 가장 좋은지 비교하고 선정하는 것
- 이러한 비교를 통해 어떤 모델이 가장 좋은 성능을 보였음을 시사하는 것이 최종적인 결론

서론 내용 추가
- 모델의 경량화가 필요한 이유
- 머신러닝에 비해 딥러닝 모델이 갖는 장점

모델 구현 방향성 설정
- 데이터셋의 실험 29, 31, 33은 구분하여 학습해야 함
- 현재로서 Machine Data만 사용해서 학습


[2026-02-02]

모델 성능 결과
- USAD, LTSF 모두 낮은 AUC 성능이 나오게 됨
- LSTM의 경우 높은 정확도를 확인할 수 있었음
- LSTM 논문에서 해당 데이터에 대한 증강을 적용하였고 이러한 접근이 높은 성능에 영향을 끼쳤을 거라고 생각됨

논문 이미지 추가
- 모델 비교에는 AUC 지표를 사용하고 최종 모델의 성능에는 CM과 Loss 곡선을 넣는 것이 좋아보임

모델 재학습
- LAM 9600 Metal Etch 데이터에 데이터 증강을 적용하여 재학습
- 증강으로도 성능이 좋지 않다면 TEP 데이터셋을 먼저 학습시키고 이후에 LAM 9600 데이터를 추론하는 방법을 사용할 것
- 재학습할 모델: USAD, LTSF
- 새로 학습할 모델: Transformer



[2026-02-11]


기존 전처리 코드의 문제점
- 웨이퍼 데이터가 Wafer_ID 구분없이 Sliding Window가 적용됨. 이는 슬라이딩 윈도우에 의해 생성된 시퀀스에 두 개의 Wafer 센서 데이터가 존재할 수 있음
- 이는 기존 Wafer의 센서 데이터를 왜곡할 수 있는 방법임
- 또한 학습셋에 사용된 데이터를 다시 테스트셋에 넣어서 과적합을 유발함

새로운 전처리 코드
- 센서 데이터를 Wafer_ID 별로 Sliding Windwo를 적용함.
- 학습셋: 정상 데이터(80%), 테스트셋: 정상 데이터(20%), 불량 데이터(100%)


모델 성능 결과
- USAD, Anomaly Transformer: 새로운 전처리 코드를 적용했어도 결과가 좋지 않았음
- TranAD의 경우 기존 전처리 코드를 사용하였을 때 0.7 정도의 AUC가 나타남. 역시 결과가 좋지 않았음
- LTSF의 경우 기존 전처리 코드를 사용하였을 때 0.6 ~ 0.8 정도의 AUC가 나타남. 역시 결과가 좋지 않았음 선행연구에서 SMT2020 데이터를 어떻게 Queue time 최적화에 사용했는지 학습
- SMT2020 2번 데이터셋 (연구개발 단계 제품, 다품종 소량생산) 사용으로 잠정 결정


논문작업
- Introduction: 공부한 내용을 바탕으로 내용을 기재하고 Reference까지 찾기


[2026-01-19]
연구 주제 변경
- SMT 2020 데이터셋의 선행 연구에서 시뮬레이션 작업이 필수적으로 요구되었으며 1달 남짓 남게된 시점에서 너무 무리한 작업이라고 판단되어 연구 주제를 변경함
- 이로 인하여 기존 데이터셋을 포함하여 조사하였고 그 중에 LAM 9600 Metal Etch Data를 선정하여 연구 주제를 정하였음
- 새롭게 정한 연구 주제는 딥러닝 모델 기반 장비 이상 유무 탐지로 정하였다.

작업 
- 논문 틀 잡기 (이성재)
- 선행 연구 조사
- 데이터셋 공부 (LAM 9600 Metal Etch Data)
- 모델 선정
- 훈련 코드 작성

업무 효율 개선
- 작업 진행마다 보고
- 어려운 부분이나 진행이 막힌 부분이 있다면 바로 카톡으로 소통


[2026-01-26]

논문 방향성 수립
- LAM 9600 데이터셋을 기반으로 다양한 딥러닝 모델을 적용하여 각 모델의 성능과 경량화를 기준으로 어떤 모델이 가장 좋은지 비교하고 선정하는 것
- 이러한 비교를 통해 어떤 모델이 가장 좋은 성능을 보였음을 시사하는 것이 최종적인 결론

서론 내용 추가
- 모델의 경량화가 필요한 이유
- 머신러닝에 비해 딥러닝 모델이 갖는 장점

모델 구현 방향성 설정
- 데이터셋의 실험 29, 31, 33은 구분하여 학습해야 함
- 현재로서 Machine Data만 사용해서 학습


[2026-02-02]

모델 성능 결과
- USAD, LTSF 모두 낮은 AUC 성능이 나오게 됨
- LSTM의 경우 높은 정확도를 확인할 수 있었음
- LSTM 논문에서 해당 데이터에 대한 증강을 적용하였고 이러한 접근이 높은 성능에 영향을 끼쳤을 거라고 생각됨

논문 이미지 추가
- 모델 비교에는 AUC 지표를 사용하고 최종 모델의 성능에는 CM과 Loss 곡선을 넣는 것이 좋아보임

모델 재학습
- LAM 9600 Metal Etch 데이터에 데이터 증강을 적용하여 재학습
- 증강으로도 성능이 좋지 않다면 TEP 데이터셋을 먼저 학습시키고 이후에 LAM 9600 데이터를 추론하는 방법을 사용할 것
- 재학습할 모델: USAD, LTSF
- 새로 학습할 모델: Transformer



[2026-02-11]


기존 전처리 코드의 문제점
- 웨이퍼 데이터가 Wafer_ID 구분없이 Sliding Window가 적용됨. 이는 슬라이딩 윈도우에 의해 생성된 시퀀스에 두 개의 Wafer 센서 데이터가 존재할 수 있음
- 이는 기존 Wafer의 센서 데이터를 왜곡할 수 있는 방법임
- 또한 학습셋에 사용된 데이터를 다시 테스트셋에 넣어서 과적합을 유발함

새로운 전처리 코드
- 센서 데이터를 Wafer_ID 별로 Sliding Windwo를 적용함.
- 학습셋: 정상 데이터(80%), 테스트셋: 정상 데이터(20%), 불량 데이터(100%)


모델 성능 결과
- USAD, Anomaly Transformer: 새로운 전처리 코드를 적용하였을 때 0.7 ~ 0.8 정도의 AUC가 나타남. 예상보다 결과가 좋지 않았음
- TranAD의 경우 기존 전처리 코드를 사용하였을 때 0.7 정도의 AUC가 나타남. 역시 결과가 좋지 않았음
- LTSF의 경우 기존 전처리 코드를 사용하였을 때 0.6 ~ 0.8 정도의 AUC가 나타남. 역시 결과가 좋지 않았음


현재 프로젝트에서의 문제점
- 전처리 과정의 확신이 없음 (해당 과정이 LAM 9600 데이터셋에 적합한지, 올바르게 적용한지)
- 최신 모델이 LAM 9600 Metal Etch 데이터를 학습함에 있어 최적화되지 않음.
- USAD와 Anomaly Transformer의 경우 해당 논문에서 사용된 데이터셋이 모두 더 긴 시간, 더 많은 센서, 더 많은 양이 존재함을 감안하면 
최신 모델은 상대적으로 적은 양의 LAM9600 데이터셋을 학습함에 있어 특별한 성능 향상이 없다고 생각됨


해야 할 일

전처리 과정 재검토
- 해당 과정이 논리적으로 적합해야 모델 훈련에 있어 동일한 성능 비교가 가능하기 때문에
- LAM9600 데이터를 어떻게 전처리해야 하는지에 대한 추가조사가 필요함. (심층적으로 조사하지 않아도 대략 어떤 방식이 있었는지에 대한 조사가 빨리 진행되어야 함)


기존 모델 재훈련, 새로운 모델 훈련 및 추론
- 이성재: 1D-CNN AE, Anomaly Tran, VTimesNet
- 용규순: LSTM, TranAD, 1D ResNet
- 류병석: LTSF, LOF_IF_OCC


새로운 모델 (VTimesNet, 1D ResNet, LOF_IF_OCC)
- 다음의 새 모델의 경우 현 프로젝트에 적합한 모델을 선정하여 추가함 (이전 모델의 경우 단순 최신 모델이었을 뿐, 데이터셋이 적합하지 않았음)
- 각 논문의 모델은 LAM9600 식각 공정, 식각 공정, 확산 공정의 데이터셋을 사용하여 연구를 진행함
- 위 논문은 반도체 공정의 센서 데이터를 사용한 모델로 Transformer, USAD보다 더 적합할 것으로 생각되어 추가하게 됨




